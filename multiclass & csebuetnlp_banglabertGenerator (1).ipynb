{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9Zp1-Cc9vMVu"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 4.7 MB 8.3 MB/s \n","\u001b[K     |████████████████████████████████| 120 kB 78.4 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 52.4 MB/s \n","\u001b[?25h"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3370,"status":"ok","timestamp":1661775955382,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"63_qqQnMvhs8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm.auto import tqdm\n","import tensorflow as tf\n","from transformers import BertTokenizer\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer,BertTokenizer"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1661775984078,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"iTgn-8HKwOBh"},"outputs":[],"source":["df = pd.read_csv('/content/sample_data/Sentiment_analysis_data.csv')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1661775986543,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"0PPnl5SVwYuj","outputId":"3f52b2cf-b202-494a-ddc3-291e3992feff"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-719bece4-1793-4dcb-94a9-e45f9697fe38\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eComment\u003c/th\u003e\n","      \u003cth\u003eTag\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e91\u003c/th\u003e\n","      \u003ctd\u003eবিগত ৩০ বছরে লুটপাট কম হলে এতোদিনে মধ্যম আয়ের ...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e12101\u003c/th\u003e\n","      \u003ctd\u003eবিএনপি সন্ত্রাসী কর্মকাণ্ডের মাধ্যমে ষড়যন্ত্র ...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1371\u003c/th\u003e\n","      \u003ctd\u003eভাল উদ্যোগ। স্বাগতম।\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e10102\u003c/th\u003e\n","      \u003ctd\u003eআর সেই মার্শকেই তার নিজের দেশের মাটিতে ধুলিস্ম...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e9451\u003c/th\u003e\n","      \u003ctd\u003eহায়রে মেসি তুমি শুধুই বার্সার\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3399\u003c/th\u003e\n","      \u003ctd\u003eশ্রীলংকার খারাপ অবস্থাও বাংলাদেশের স্বাভাবিক অ...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e12080\u003c/th\u003e\n","      \u003ctd\u003eআমাদের দেশের মানুষ অনেক অসচেতন।\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e900\u003c/th\u003e\n","      \u003ctd\u003eপাগলে কিনা কয়আর ছাগলে পাতা চিবায়\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3805\u003c/th\u003e\n","      \u003ctd\u003eপ্রত্যেক কেন্দ্র কেন্দ্রে ভোটের ফল ঘোষনা করতে ...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e8156\u003c/th\u003e\n","      \u003ctd\u003eব্যাংক ডাকাতদের আইনের অাওতায় আনা বাঞ্চনীয়\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-719bece4-1793-4dcb-94a9-e45f9697fe38')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-719bece4-1793-4dcb-94a9-e45f9697fe38 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-719bece4-1793-4dcb-94a9-e45f9697fe38');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                                                 Comment  Tag\n","91     বিগত ৩০ বছরে লুটপাট কম হলে এতোদিনে মধ্যম আয়ের ...    0\n","12101  বিএনপি সন্ত্রাসী কর্মকাণ্ডের মাধ্যমে ষড়যন্ত্র ...    0\n","1371                                ভাল উদ্যোগ। স্বাগতম।    1\n","10102  আর সেই মার্শকেই তার নিজের দেশের মাটিতে ধুলিস্ম...    0\n","9451                       হায়রে মেসি তুমি শুধুই বার্সার    0\n","3399   শ্রীলংকার খারাপ অবস্থাও বাংলাদেশের স্বাভাবিক অ...    0\n","12080                    আমাদের দেশের মানুষ অনেক অসচেতন।    0\n","900                     পাগলে কিনা কয়আর ছাগলে পাতা চিবায়    0\n","3805   প্রত্যেক কেন্দ্র কেন্দ্রে ভোটের ফল ঘোষনা করতে ...    1\n","8156           ব্যাংক ডাকাতদের আইনের অাওতায় আনা বাঞ্চনীয়    1"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df = df.sample(frac=1)\n","df.tail(10)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":750,"status":"ok","timestamp":1661775990850,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"PhffJPrvwd4i","outputId":"2f5298ab-eb9c-4e9f-b1ce-f1920a8cc514"},"outputs":[{"data":{"text/plain":["1    10269\n","0     9747\n","2     2951\n","Name: Tag, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df['Tag'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVnKhwelfNxM"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(\"csebuetnlp/banglabert_generator\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1661776000521,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"YsviUsKyx4Nk","outputId":"6d7b2f67-1992-4333-fe92-0d377359c7b1"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'এদের জন্য ফারমার্স ব্যাংক আদর্শ!'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df['Comment'].iloc[0]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":585,"status":"ok","timestamp":1661776003644,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"snsOUowYyI4a","outputId":"f8141173-2f19-4128-837e-ec941529dc81"},"outputs":[{"name":"stderr","output_type":"stream","text":["Keyword arguments {'return_tensor': 'tf'} not recognized.\n"]}],"source":["token = tokenizer.encode_plus(\n","    df['Comment'].iloc[0],\n","    max_length = 256,\n","    truncation=True,\n","    padding='max_length',\n","    add_special_tokens=True,\n","    return_tensor='tf'\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661776006089,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"lI1Ng9-ny1ht"},"outputs":[],"source":["x_input_ids = np.zeros((len(df),256))\n","x_attention_mask = np.zeros((len(df),256))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1661776010166,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"8N35galdzj5U"},"outputs":[],"source":["def generate_training_data(df,ids,masks,tokenizer):\n","  for i, text in tqdm(enumerate(df['Comment'])):\n","    tokenized_text = tokenizer.encode_plus(\n","        text,\n","        max_length=256,\n","        truncation=True,\n","        padding = 'max_length',\n","        add_special_tokens=True,\n","        return_tensors='tf'\n","    )\n","    ids[i, :] = tokenized_text.input_ids\n","    masks[i,:]= tokenized_text.attention_mask\n","  return ids,masks"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"elapsed":16118,"status":"ok","timestamp":1661776031845,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"UgWYDxQN1Lti","outputId":"bc0fdbb3-b08e-4127-87b2-8a0ef449218a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aad6cf07ba004365b1594c9291d146a7","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["x_input_ids,x_attention_mask=generate_training_data(df,x_input_ids,x_attention_mask,tokenizer)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1661776035257,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"JbGuCEdY1vAQ","outputId":"fb30bbb6-32d3-46df-d37f-78520f2a11bb"},"outputs":[{"data":{"text/plain":["array([[2.000e+00, 2.824e+03, 9.000e+02, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [2.000e+00, 1.103e+03, 1.839e+03, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [2.000e+00, 1.418e+03, 2.111e+03, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       ...,\n","       [2.000e+00, 4.433e+03, 4.100e+02, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [2.000e+00, 3.866e+03, 1.947e+03, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00],\n","       [2.000e+00, 3.182e+03, 7.395e+03, ..., 0.000e+00, 0.000e+00,\n","        0.000e+00]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["x_input_ids"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":348,"status":"ok","timestamp":1661776038076,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"0duByHXU12uG"},"outputs":[],"source":["labels = np.zeros((len(df),3))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661776041208,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"5GP--y0w2Grb"},"outputs":[],"source":["labels[np.arange(len(df)),df['Tag'].values]=1"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":452,"status":"ok","timestamp":1661776041969,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"6lruqIwm25Jn"},"outputs":[],"source":["dataset = tf.data.Dataset.from_tensor_slices((x_input_ids,x_attention_mask,labels))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661776042536,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"VI5aWGOY3RTe","outputId":"9773311c-9bf3-4251-ace1-56d88925a7d6"},"outputs":[{"data":{"text/plain":["\u003cTakeDataset element_spec=(TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(3,), dtype=tf.float64, name=None))\u003e"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["dataset.take(1)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661776043830,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"2-0WbqBk3-ak"},"outputs":[],"source":["def SentimentDatasetMapFunction(input_ids,attention_mask,labels):\n","  return{\n","      'input_ids':input_ids,\n","      'attention_mask':attention_mask\n","  }, labels"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":612,"status":"ok","timestamp":1661776046947,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"lKHJS6wG4qix"},"outputs":[],"source":["dataset = dataset.map(SentimentDatasetMapFunction)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661776047279,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"sUbvA2s44xny","outputId":"f4c18065-db28-4acc-9edd-74d1beb25ce4"},"outputs":[{"data":{"text/plain":["\u003cTakeDataset element_spec=({'input_ids': TensorSpec(shape=(256,), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(256,), dtype=tf.float64, name=None)}, TensorSpec(shape=(3,), dtype=tf.float64, name=None))\u003e"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["dataset.take(1)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1661776048987,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"CEYCtsuy5BXB"},"outputs":[],"source":["dataset = dataset.shuffle(10000).batch(16,drop_remainder=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":502,"status":"ok","timestamp":1661776052282,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"tZmNRvwy6jOp"},"outputs":[],"source":["p=14\n","train_size = int((len(df)//16)*p)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661776053347,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"CfvxzmkX7UIQ","outputId":"109a49a1-847a-496e-e7ff-53edc41344ec"},"outputs":[{"data":{"text/plain":["20090"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["train_size"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661776054128,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"aVScqu6x7WiL"},"outputs":[],"source":["train_dataset = dataset.take(train_size)\n","val_dataset = dataset.skip(train_size)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":2682,"status":"ok","timestamp":1661776065536,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"TG2YwT-x78YF"},"outputs":[],"source":["from transformers import TFBertModel"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":7105,"status":"ok","timestamp":1661776094442,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"1YBadeQa8Dkm","outputId":"80a1d81c-4378-49b0-f930-0b452426be59"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4843725a233b40fd849c37ad5e7e538b","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/133M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'generator_predictions.LayerNorm.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'generator_predictions.dense.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.1.intermediate.dense.weight', 'generator_lm_head.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'generator_lm_head.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.8.output.LayerNorm.weight', 'generator_predictions.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'generator_predictions.dense.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.embeddings.position_ids', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.embeddings_project.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["bert_Model = TFBertModel.from_pretrained(\"csebuetnlp/banglabert_generator\",from_pt=True)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5414,"status":"ok","timestamp":1661776109078,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"VVo6Cqsi8Onu","outputId":"7bdd0967-4b24-4788-d3a0-88570e758f81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 256)]        0           []                               \n","                                                                                                  \n"," attention_mask (InputLayer)    [(None, 256)]        0           []                               \n","                                                                                                  \n"," bert (TFBertMainLayer)         TFBaseModelOutputWi  17867008    ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 256,                                               \n","                                 256),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 256),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," intermediate_layer (Dense)     (None, 512)          131584      ['bert[0][1]']                   \n","                                                                                                  \n"," output_layer (Dense)           (None, 3)            1539        ['intermediate_layer[0][0]']     \n","                                                                                                  \n","==================================================================================================\n","Total params: 18,000,131\n","Trainable params: 18,000,131\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["input_ids = tf.keras.layers.Input(shape=(256,),name='input_ids',dtype='int32')\n","attention_masks = tf.keras.layers.Input(shape=(256,),name='attention_mask',dtype='int32')\n","\n","bert_embds = bert_Model.bert(input_ids,attention_mask=attention_masks)[1]\n","intermediate_layer = tf.keras.layers.Dense(512,activation='relu',name='intermediate_layer')(bert_embds)\n","output_layer = tf.keras.layers.Dense(3,activation='softmax',name='output_layer')(intermediate_layer)\n","\n","model = tf.keras.Model(inputs=[input_ids,attention_masks],outputs=output_layer)\n","model.summary()"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1661776113565,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"iHqjBI0c_Bt7"},"outputs":[],"source":["optim = tf.keras.optimizers.Adam(learning_rate=1e-5,decay=1e-6)\n","loss_func = tf.keras.losses.CategoricalCrossentropy()\n","acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1661776115876,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"PFluL-mU_suu"},"outputs":[],"source":["model.compile(optimizer=optim,loss=loss_func,metrics=[acc])"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264970,"status":"ok","timestamp":1661776382854,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"CDhzOXQa__F-","outputId":"ad81a37e-4ed3-47f6-8311-18a727e90d20"},"outputs":[{"name":"stdout","output_type":"stream","text":["1435/1435 [==============================] - 265s 178ms/step - loss: 0.8356 - accuracy: 0.6094\n"]}],"source":["hist = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=1\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28150,"status":"ok","timestamp":1661777378617,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"xOi2Ugua8073","outputId":"b0d76a0a-7523-4cc4-ffad-a428a2d41377"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"]}],"source":["model.save('sentiment_model')"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":13118,"status":"ok","timestamp":1661777395755,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"},"user_tz":-360},"id":"FG1yokZZOEMA"},"outputs":[],"source":["loaded_model = tf.keras.models.load_model('sentiment_model')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"multiclass \u0026 csebuetnlp_banglabertGenerator.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1b5efed87df94a0a8f5be13f467db057":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20aa1b7d864c4bdb965adce0965f0fb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8724532a959d4555b1ef8418f86adbcb","placeholder":"​","style":"IPY_MODEL_84b4f84366654143bf79cdeda3c3387f","value":""}},"3498fc9471134a88bbbbcec837c05bcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84ad0729e4124f89a1702db03574ede2","placeholder":"​","style":"IPY_MODEL_a98f388b86914011a762dffda0c9e5d6","value":" 133M/133M [00:02\u0026lt;00:00, 58.8MB/s]"}},"359e4236e47e4d02bc264618ab7ee4e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d2d9665fd9d4cbc9b294a8be994cd27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"443f016f174f49c19b41c925ce3c5c3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb0e408ce374f2284cf826a77735e58","placeholder":"​","style":"IPY_MODEL_3d2d9665fd9d4cbc9b294a8be994cd27","value":"Downloading pytorch_model.bin: 100%"}},"4843725a233b40fd849c37ad5e7e538b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_443f016f174f49c19b41c925ce3c5c3f","IPY_MODEL_f9860e280e2a44dc98b047068ffb9958","IPY_MODEL_3498fc9471134a88bbbbcec837c05bcb"],"layout":"IPY_MODEL_5000055d9b6549c4b6598c9c05984221"}},"4e0870321b83428eb9432da4635d53e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5000055d9b6549c4b6598c9c05984221":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63d1254b5ac4418f860df7aef902bcb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66187b88cecd4eb6be9eac7d1717cdba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73e7b36ed6e94444bfbea7dedac0bf29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84ad0729e4124f89a1702db03574ede2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b4f84366654143bf79cdeda3c3387f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85b23c0f235b43009e2317cfa9b0a770":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8724532a959d4555b1ef8418f86adbcb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a98f388b86914011a762dffda0c9e5d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad6cf07ba004365b1594c9291d146a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20aa1b7d864c4bdb965adce0965f0fb4","IPY_MODEL_e162b53b2c26494893511287dd9e1850","IPY_MODEL_e64ef922c74b47dd93a43f02d4bf9beb"],"layout":"IPY_MODEL_85b23c0f235b43009e2317cfa9b0a770"}},"afb0e408ce374f2284cf826a77735e58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e162b53b2c26494893511287dd9e1850":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e0870321b83428eb9432da4635d53e5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63d1254b5ac4418f860df7aef902bcb5","value":1}},"e64ef922c74b47dd93a43f02d4bf9beb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_359e4236e47e4d02bc264618ab7ee4e6","placeholder":"​","style":"IPY_MODEL_1b5efed87df94a0a8f5be13f467db057","value":" 22967/? [00:15\u0026lt;00:00, 1787.24it/s]"}},"f9860e280e2a44dc98b047068ffb9958":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66187b88cecd4eb6be9eac7d1717cdba","max":139597732,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73e7b36ed6e94444bfbea7dedac0bf29","value":139597732}}}}},"nbformat":4,"nbformat_minor":0}