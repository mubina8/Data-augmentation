{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multiclass & csebuetnlp_banglabertT5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"342a3c46c4b548ee99f1a73030eadcf3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32807d6db46042228d438af5db6eb7e5","IPY_MODEL_db6948f1de724509980e2f4bc499e8c0","IPY_MODEL_abb7ee30d1084e7496c5a77410dfb6b7"],"layout":"IPY_MODEL_a3ffbc9958e14536a7b53b18ad2df41c"}},"32807d6db46042228d438af5db6eb7e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79183e8075fd4c4f88864f6c79b6f34f","placeholder":"​","style":"IPY_MODEL_b144dcba4b524c869ad8834d25fe3c49","value":""}},"db6948f1de724509980e2f4bc499e8c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee386fa279dd4589a4aea6e7c41d1855","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a73d7ca4667041f28c147af837ca47c5","value":1}},"abb7ee30d1084e7496c5a77410dfb6b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a50d1dc4c9a4b968978279640de920b","placeholder":"​","style":"IPY_MODEL_4af2ad0f4444468c975ed87c263705ca","value":" 22967/? [00:18&lt;00:00, 1625.22it/s]"}},"a3ffbc9958e14536a7b53b18ad2df41c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79183e8075fd4c4f88864f6c79b6f34f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b144dcba4b524c869ad8834d25fe3c49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee386fa279dd4589a4aea6e7c41d1855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a73d7ca4667041f28c147af837ca47c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a50d1dc4c9a4b968978279640de920b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4af2ad0f4444468c975ed87c263705ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a32072a2bb8a4f0097745a37f4244a17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88eabab0f5cf45a5a2e8da67d9072fd9","IPY_MODEL_93a539b8c8fd4f91b81cebd01066a91a","IPY_MODEL_998a4a27e92e4d1eb43e3e91aff6abb0"],"layout":"IPY_MODEL_f20c798309904bf5a2850b95804b5d31"}},"88eabab0f5cf45a5a2e8da67d9072fd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_238ae51ed12d4e78a5f7ee2187e9a1e0","placeholder":"​","style":"IPY_MODEL_4f26825cd2954abd92975b50e137766c","value":"Downloading pytorch_model.bin: 100%"}},"93a539b8c8fd4f91b81cebd01066a91a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0668f38866ff47bea7def5437b4153d5","max":990441433,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3fb4997b9ee4b1ebd7159cd45f04b77","value":990441433}},"998a4a27e92e4d1eb43e3e91aff6abb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34e116417d494b708ef8715801ccbe1a","placeholder":"​","style":"IPY_MODEL_882143c9dbf64c2cb9a66f6e9a879776","value":" 945M/945M [00:17&lt;00:00, 64.7MB/s]"}},"f20c798309904bf5a2850b95804b5d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"238ae51ed12d4e78a5f7ee2187e9a1e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f26825cd2954abd92975b50e137766c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0668f38866ff47bea7def5437b4153d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3fb4997b9ee4b1ebd7159cd45f04b77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34e116417d494b708ef8715801ccbe1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"882143c9dbf64c2cb9a66f6e9a879776":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9Zp1-Cc9vMVu","executionInfo":{"status":"ok","timestamp":1661781031701,"user_tz":-360,"elapsed":3247,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"outputs":[],"source":["!pip install -q transformers"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from tqdm.auto import tqdm\n","import tensorflow as tf\n","from transformers import BertTokenizer,T5TokenizerFast\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"],"metadata":{"id":"63_qqQnMvhs8","executionInfo":{"status":"ok","timestamp":1661781034374,"user_tz":-360,"elapsed":2678,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/sample_data/Sentiment_analysis_data.csv')\n"],"metadata":{"id":"iTgn-8HKwOBh","executionInfo":{"status":"ok","timestamp":1661781034375,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = df.sample(frac=1)\n","df.tail(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"0PPnl5SVwYuj","outputId":"d7ce0cb1-8c0b-4792-8096-7cad2a756bb5","executionInfo":{"status":"ok","timestamp":1661781034921,"user_tz":-360,"elapsed":552,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 Comment  Tag\n","160    তা বাংলাদেশের যারা চুরির সাথে জড়িত তাদের শাস্ত...    1\n","8556   তাহলে বর্তমান অর্থমন্ত্রী কি দুর্বল? আসলে শুধু...    0\n","517    আহারে! লাখ তিনেক টাকার জন্য কত হামাগুড়ি দিচ্ছি...    0\n","10303  আমাদের সৌভাগ্য শচীনের পর বিরাটকে পেয়েছি। তা না...    1\n","4631   নির্বাচনে শান্তিপূর্ন মিছিল মিটিং এর সুযোগ থাক...    0\n","17149   অসাধারণ একটা নাটক নিশো ভাইয়ের কোনো তুলনা হয়না...    1\n","9911   না তারা পারেনি। ১৫৬ তে অল আউট। আজিজ প্যাটেল ৩ ...    0\n","13307                রেলের টাকা যায় সরকারী লোকদের পকেটে    0\n","8470     ডিজিটাল হুন্ডি বন্ধ না হলে এই ধারা অব্যহত থাকবে    1\n","8520   ২০১৪ সালের ফেব্রুয়ারি মাসে আমি মোটামুটি ফাঁকাই...    2"],"text/html":["\n","  <div id=\"df-847a3086-9673-4ac1-8f35-1ad77ee66e9f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Comment</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>160</th>\n","      <td>তা বাংলাদেশের যারা চুরির সাথে জড়িত তাদের শাস্ত...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8556</th>\n","      <td>তাহলে বর্তমান অর্থমন্ত্রী কি দুর্বল? আসলে শুধু...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>517</th>\n","      <td>আহারে! লাখ তিনেক টাকার জন্য কত হামাগুড়ি দিচ্ছি...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10303</th>\n","      <td>আমাদের সৌভাগ্য শচীনের পর বিরাটকে পেয়েছি। তা না...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4631</th>\n","      <td>নির্বাচনে শান্তিপূর্ন মিছিল মিটিং এর সুযোগ থাক...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17149</th>\n","      <td>অসাধারণ একটা নাটক নিশো ভাইয়ের কোনো তুলনা হয়না...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9911</th>\n","      <td>না তারা পারেনি। ১৫৬ তে অল আউট। আজিজ প্যাটেল ৩ ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13307</th>\n","      <td>রেলের টাকা যায় সরকারী লোকদের পকেটে</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8470</th>\n","      <td>ডিজিটাল হুন্ডি বন্ধ না হলে এই ধারা অব্যহত থাকবে</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8520</th>\n","      <td>২০১৪ সালের ফেব্রুয়ারি মাসে আমি মোটামুটি ফাঁকাই...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-847a3086-9673-4ac1-8f35-1ad77ee66e9f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-847a3086-9673-4ac1-8f35-1ad77ee66e9f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-847a3086-9673-4ac1-8f35-1ad77ee66e9f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df['Tag'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhffJPrvwd4i","outputId":"ea36e6ea-cc6e-49f5-f2bc-005f5da6f29a","executionInfo":{"status":"ok","timestamp":1661781034921,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    10269\n","0     9747\n","2     2951\n","Name: Tag, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["!pip install sentencepiece\n","!wget https://raw.githubusercontent.com/google/sentencepiece/master/data/botchan.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APRSqDMCtXB-","executionInfo":{"status":"ok","timestamp":1661781038556,"user_tz":-360,"elapsed":3639,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}},"outputId":"b4fa87d7-4b2c-415b-dbf3-ec1604bb4378"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n","--2022-08-29 13:50:37--  https://raw.githubusercontent.com/google/sentencepiece/master/data/botchan.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 278779 (272K) [text/plain]\n","Saving to: ‘botchan.txt.1’\n","\n","botchan.txt.1       100%[===================>] 272.25K  --.-KB/s    in 0.005s  \n","\n","2022-08-29 13:50:37 (57.0 MB/s) - ‘botchan.txt.1’ saved [278779/278779]\n","\n"]}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5\",use_fast=False)"],"metadata":{"id":"vVnKhwelfNxM","executionInfo":{"status":"ok","timestamp":1661781039136,"user_tz":-360,"elapsed":586,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df['Comment'].iloc[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"YsviUsKyx4Nk","outputId":"509fa1c3-caf2-4685-8771-ea2463e37003","executionInfo":{"status":"ok","timestamp":1661781039137,"user_tz":-360,"elapsed":25,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'উদ্দিপ্ত হবার জন্যে উপলক্ষ খুঁজে নেওয়া মন্দ না। তবে কাজের থেকে যেন কথা বেশি না হিয়ে যায় সেটাও বিবেচ্য। আবেগের অনিয়ন্ত্রিত প্রকাশের ধাক্কা সবাই নিয়ন্ত্রন করতে পারে না। মুশফিক এর আগে ২-৩ দফায় দেখিয়েছে যে এই কারনে তীরে এসে তার তরী ডোবে। আশা  করা যায় যে সে এর থেকে শিখেছে। বাস্তবে ওরকম পরিস্থিতীতে তার সাফল্য আবার না দেখা পর্যন্ত তাকেও এটা মানতে হবে যে তার কাজ এখন অনেক বাকি।'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["token = tokenizer.encode_plus(\n","    df['Comment'].iloc[0],\n","    max_length = 256,\n","    truncation=True,\n","    padding='max_length',\n","    add_special_tokens=True,\n","    return_tensor='tf'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snsOUowYyI4a","outputId":"0bc4b345-e976-4a07-e73c-e3ff7e270303","executionInfo":{"status":"ok","timestamp":1661781039138,"user_tz":-360,"elapsed":22,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Keyword arguments {'return_tensor': 'tf'} not recognized.\n"]}]},{"cell_type":"code","source":["x_input_ids = np.zeros((len(df),256))\n","x_attention_mask = np.zeros((len(df),256))\n"],"metadata":{"id":"lI1Ng9-ny1ht","executionInfo":{"status":"ok","timestamp":1661781039138,"user_tz":-360,"elapsed":14,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate_training_data(df,ids,masks,tokenizer):\n","  for i, text in tqdm(enumerate(df['Comment'])):\n","    tokenized_text = tokenizer.encode_plus(\n","        text,\n","        max_length=256,\n","        truncation=True,\n","        padding = 'max_length',\n","        add_special_tokens=True,\n","        return_tensors='tf'\n","    )\n","    ids[i, :] = tokenized_text.input_ids\n","    masks[i,:]= tokenized_text.attention_mask\n","  return ids,masks"],"metadata":{"id":"8N35galdzj5U","executionInfo":{"status":"ok","timestamp":1661781039139,"user_tz":-360,"elapsed":14,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["x_input_ids,x_attention_mask=generate_training_data(df,x_input_ids,x_attention_mask,tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["342a3c46c4b548ee99f1a73030eadcf3","32807d6db46042228d438af5db6eb7e5","db6948f1de724509980e2f4bc499e8c0","abb7ee30d1084e7496c5a77410dfb6b7","a3ffbc9958e14536a7b53b18ad2df41c","79183e8075fd4c4f88864f6c79b6f34f","b144dcba4b524c869ad8834d25fe3c49","ee386fa279dd4589a4aea6e7c41d1855","a73d7ca4667041f28c147af837ca47c5","0a50d1dc4c9a4b968978279640de920b","4af2ad0f4444468c975ed87c263705ca"]},"id":"UgWYDxQN1Lti","outputId":"df13df76-7b82-4e3a-f307-d97cb2faf6a9","executionInfo":{"status":"ok","timestamp":1661781057278,"user_tz":-360,"elapsed":18153,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342a3c46c4b548ee99f1a73030eadcf3"}},"metadata":{}}]},{"cell_type":"code","source":["x_input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbGuCEdY1vAQ","outputId":"28114c7f-fe7e-4121-afe3-a645c84a0566","executionInfo":{"status":"ok","timestamp":1661781057278,"user_tz":-360,"elapsed":18,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 3508.,  1132.,  5352., ...,     0.,     0.,     0.],\n","       [   63.,   426., 12572., ...,     0.,     0.,     0.],\n","       [  481.,  1080.,   167., ...,     0.,     0.,     0.],\n","       ...,\n","       [ 8617.,   164.,    54., ...,     0.,     0.,     0.],\n","       [ 3405.,  1534.,  5733., ...,     0.,     0.,     0.],\n","       [ 2435.,   308.,  1814., ...,     0.,     0.,     0.]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["labels = np.zeros((len(df),3))"],"metadata":{"id":"0duByHXU12uG","executionInfo":{"status":"ok","timestamp":1661781057859,"user_tz":-360,"elapsed":594,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["labels[np.arange(len(df)),df['Tag'].values]=1"],"metadata":{"id":"5GP--y0w2Grb","executionInfo":{"status":"ok","timestamp":1661781057860,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((x_input_ids,x_attention_mask,labels))"],"metadata":{"id":"6lruqIwm25Jn","executionInfo":{"status":"ok","timestamp":1661781057860,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["dataset.take(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VI5aWGOY3RTe","outputId":"63b19ad2-b0e4-46c5-adfa-7be843263710","executionInfo":{"status":"ok","timestamp":1661781057860,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=(TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(3,), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def SentimentDatasetMapFunction(input_ids,attention_mask,labels):\n","  return{\n","      'input_ids':input_ids,\n","      'attention_mask':attention_mask\n","  }, labels"],"metadata":{"id":"2-0WbqBk3-ak","executionInfo":{"status":"ok","timestamp":1661781057861,"user_tz":-360,"elapsed":4,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.map(SentimentDatasetMapFunction)"],"metadata":{"id":"lKHJS6wG4qix","executionInfo":{"status":"ok","timestamp":1661781058390,"user_tz":-360,"elapsed":533,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["dataset.take(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUbvA2s44xny","outputId":"678e7ac0-5fa3-49ff-f213-ae2445180df6","executionInfo":{"status":"ok","timestamp":1661781058390,"user_tz":-360,"elapsed":8,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(256,), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(256,), dtype=tf.float64, name=None)}, TensorSpec(shape=(3,), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["dataset = dataset.shuffle(10000).batch(16,drop_remainder=True)"],"metadata":{"id":"CEYCtsuy5BXB","executionInfo":{"status":"ok","timestamp":1661781058390,"user_tz":-360,"elapsed":6,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["p=14\n","train_size = int((len(df)//16)*p)"],"metadata":{"id":"tZmNRvwy6jOp","executionInfo":{"status":"ok","timestamp":1661781058391,"user_tz":-360,"elapsed":7,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfvxzmkX7UIQ","outputId":"f9a8d3e6-21bf-486b-8d64-6e8f9f30308c","executionInfo":{"status":"ok","timestamp":1661781058391,"user_tz":-360,"elapsed":7,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20090"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["train_dataset = dataset.take(train_size)\n","val_dataset = dataset.skip(train_size)"],"metadata":{"id":"aVScqu6x7WiL","executionInfo":{"status":"ok","timestamp":1661781058391,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from transformers import TFBertModel"],"metadata":{"id":"TG2YwT-x78YF","executionInfo":{"status":"ok","timestamp":1661781058391,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["bert_Model = TFBertModel.from_pretrained(\"csebuetnlp/banglat5\",from_pt=True)"],"metadata":{"id":"1YBadeQa8Dkm","colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["a32072a2bb8a4f0097745a37f4244a17","88eabab0f5cf45a5a2e8da67d9072fd9","93a539b8c8fd4f91b81cebd01066a91a","998a4a27e92e4d1eb43e3e91aff6abb0","f20c798309904bf5a2850b95804b5d31","238ae51ed12d4e78a5f7ee2187e9a1e0","4f26825cd2954abd92975b50e137766c","0668f38866ff47bea7def5437b4153d5","d3fb4997b9ee4b1ebd7159cd45f04b77","34e116417d494b708ef8715801ccbe1a","882143c9dbf64c2cb9a66f6e9a879776"]},"executionInfo":{"status":"ok","timestamp":1661781081466,"user_tz":-360,"elapsed":23080,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}},"outputId":"850acbf0-65c9-497b-9c23-b85f33835d88"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type t5 to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/945M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a32072a2bb8a4f0097745a37f4244a17"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['decoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'encoder.block.7.layer.0.layer_norm.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.embed_tokens.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 'encoder.block.6.layer.1.DenseReluDense.wo.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'shared.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.final_layer_norm.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.1.layer_norm.weight', 'encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'encoder.block.8.layer.1.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'encoder.block.4.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.11.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'encoder.block.7.layer.1.layer_norm.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'encoder.block.10.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.10.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'encoder.block.9.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'encoder.block.8.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.embed_tokens.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.1.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.6.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'encoder.block.9.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'encoder.block.7.layer.1.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.final_layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'encoder.block.8.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'encoder.block.10.layer.1.DenseReluDense.wo.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'lm_head.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["input_ids = tf.keras.layers.Input(shape=(256,),name='input_ids',dtype='int32')\n","attention_masks = tf.keras.layers.Input(shape=(256,),name='attention_mask',dtype='int32')\n","\n","bert_embds = bert_Model.bert(input_ids,attention_mask=attention_masks)[1]\n","intermediate_layer = tf.keras.layers.Dense(512,activation='relu',name='intermediate_layer')(bert_embds)\n","output_layer = tf.keras.layers.Dense(3,activation='softmax',name='output_layer')(intermediate_layer)\n","\n","model = tf.keras.Model(inputs=[input_ids,attention_masks],outputs=output_layer)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVo6Cqsi8Onu","outputId":"55e544d5-8542-4e84-e045-15accd6f0f28","executionInfo":{"status":"ok","timestamp":1661781086339,"user_tz":-360,"elapsed":4886,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 256)]        0           []                               \n","                                                                                                  \n"," attention_mask (InputLayer)    [(None, 256)]        0           []                               \n","                                                                                                  \n"," bert (TFBertMainLayer)         TFBaseModelOutputWi  110715648   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 256,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," intermediate_layer (Dense)     (None, 512)          393728      ['bert[0][1]']                   \n","                                                                                                  \n"," output_layer (Dense)           (None, 3)            1539        ['intermediate_layer[0][0]']     \n","                                                                                                  \n","==================================================================================================\n","Total params: 111,110,915\n","Trainable params: 111,110,915\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["optim = tf.keras.optimizers.Adam(learning_rate=1e-5,decay=1e-6)\n","loss_func = tf.keras.losses.CategoricalCrossentropy()\n","acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"],"metadata":{"id":"iHqjBI0c_Bt7","executionInfo":{"status":"ok","timestamp":1661781086339,"user_tz":-360,"elapsed":14,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=optim,loss=loss_func,metrics=[acc])"],"metadata":{"id":"PFluL-mU_suu","executionInfo":{"status":"ok","timestamp":1661781086339,"user_tz":-360,"elapsed":13,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["hist = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDhzOXQa__F-","outputId":"d3134847-e688-4c1b-9218-efdfdd6c51aa","executionInfo":{"status":"ok","timestamp":1661782257529,"user_tz":-360,"elapsed":1171203,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["1435/1435 [==============================] - 1142s 789ms/step - loss: 0.8002 - accuracy: 0.6359\n"]}]},{"cell_type":"code","source":["model.save('sentiment_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOi2Ugua8073","outputId":"dabd5718-35be-4d33-84b5-c71369a5bc49","executionInfo":{"status":"ok","timestamp":1661782288082,"user_tz":-360,"elapsed":30563,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","source":["loaded_model = tf.keras.models.load_model('sentiment_model')"],"metadata":{"id":"FG1yokZZOEMA","executionInfo":{"status":"ok","timestamp":1661782302285,"user_tz":-360,"elapsed":14217,"user":{"displayName":"Mubina Ashrafi","userId":"10774814085273026825"}}},"execution_count":32,"outputs":[]}]}